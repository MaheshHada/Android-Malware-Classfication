{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 196) (3036, 2) (338, 196) (338, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mahesh/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "%config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Dropout, InputLayer\n",
    "from keras.models import Model, Sequential\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def load_data(dirname):\n",
    "    csv_file_name = 'data/opcodes_frequency_file_' + dirname + '.csv'\n",
    "    data = pd.read_csv(csv_file_name)\n",
    "    data.drop(data.columns[[0]], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "data = load_data('Combined')\n",
    "target = data['label']\n",
    "data.drop(['label', 'apk'], axis = 1, inplace=True)\n",
    "coulmn_names = data.columns\n",
    "\n",
    "empty_columns = []\n",
    "for column in coulmn_names:\n",
    "    if data[column].sum() == 0:\n",
    "        empty_columns.append(column)\n",
    "        \n",
    "for column in empty_columns:\n",
    "    data.drop(column, axis = 1, inplace=True)\n",
    "\n",
    "data = data.values\n",
    "target = np.array(target)\n",
    "target = to_categorical(target)\n",
    "\n",
    "data_scaled = minmax_scale(data, feature_range=(0, 1), axis = 0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_scaled, target, train_size = 0.9, random_state = seed(2017))\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahesh/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "/home/mahesh/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 49)                4851      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                1600      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 49)                1617      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 98)                4900      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 196)               19404     \n",
      "=================================================================\n",
      "Total params: 51,678\n",
      "Trainable params: 51,678\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3036 samples, validate on 338 samples\n",
      "Epoch 1/100\n",
      "3036/3036 [==============================] - 1s 460us/step - loss: 0.0015 - acc: 0.1739 - val_loss: 9.6400e-04 - val_acc: 0.2544\n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s 73us/step - loss: 7.5183e-04 - acc: 0.2526 - val_loss: 7.7968e-04 - val_acc: 0.2899\n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s 82us/step - loss: 5.9832e-04 - acc: 0.2964 - val_loss: 6.7509e-04 - val_acc: 0.3491\n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s 77us/step - loss: 5.1054e-04 - acc: 0.3320 - val_loss: 6.1598e-04 - val_acc: 0.3787\n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s 67us/step - loss: 4.5124e-04 - acc: 0.3706 - val_loss: 5.6730e-04 - val_acc: 0.3994\n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s 73us/step - loss: 3.9976e-04 - acc: 0.3702 - val_loss: 5.4429e-04 - val_acc: 0.3846\n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s 82us/step - loss: 3.6997e-04 - acc: 0.4045 - val_loss: 5.1545e-04 - val_acc: 0.4053\n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s 79us/step - loss: 3.5834e-04 - acc: 0.4124 - val_loss: 4.8644e-04 - val_acc: 0.4349\n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s 69us/step - loss: 3.5161e-04 - acc: 0.4065 - val_loss: 5.0963e-04 - val_acc: 0.4497\n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s 73us/step - loss: 3.7343e-04 - acc: 0.4134 - val_loss: 5.9370e-04 - val_acc: 0.4172\n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s 70us/step - loss: 3.9077e-04 - acc: 0.4144 - val_loss: 5.4120e-04 - val_acc: 0.4527\n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s 73us/step - loss: 3.5342e-04 - acc: 0.4173 - val_loss: 5.1104e-04 - val_acc: 0.4112\n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s 68us/step - loss: 3.3465e-04 - acc: 0.4285 - val_loss: 5.1401e-04 - val_acc: 0.4349\n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s 88us/step - loss: 3.2787e-04 - acc: 0.4424 - val_loss: 5.0783e-04 - val_acc: 0.4704\n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s 77us/step - loss: 3.5321e-04 - acc: 0.4387 - val_loss: 4.7274e-04 - val_acc: 0.4379\n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s 80us/step - loss: 3.1094e-04 - acc: 0.4519 - val_loss: 5.1638e-04 - val_acc: 0.4822\n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s 71us/step - loss: 3.4452e-04 - acc: 0.4374 - val_loss: 4.6005e-04 - val_acc: 0.4112\n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s 79us/step - loss: 3.3809e-04 - acc: 0.4424 - val_loss: 4.6555e-04 - val_acc: 0.4349\n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s 84us/step - loss: 3.7932e-04 - acc: 0.4513 - val_loss: 5.2205e-04 - val_acc: 0.4497\n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s 90us/step - loss: 3.4775e-04 - acc: 0.4236 - val_loss: 4.9920e-04 - val_acc: 0.3994\n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s 74us/step - loss: 2.8507e-04 - acc: 0.4470 - val_loss: 4.1900e-04 - val_acc: 0.5030\n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s 78us/step - loss: 2.6134e-04 - acc: 0.4700 - val_loss: 4.0253e-04 - val_acc: 0.5030\n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s 79us/step - loss: 2.7768e-04 - acc: 0.4697 - val_loss: 4.2402e-04 - val_acc: 0.4852\n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s 82us/step - loss: 2.7733e-04 - acc: 0.4516 - val_loss: 4.4821e-04 - val_acc: 0.4734\n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s 90us/step - loss: 2.6661e-04 - acc: 0.4657 - val_loss: 4.0669e-04 - val_acc: 0.4556\n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s 83us/step - loss: 2.8030e-04 - acc: 0.4595 - val_loss: 4.1858e-04 - val_acc: 0.4734\n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s 84us/step - loss: 2.7810e-04 - acc: 0.4664 - val_loss: 4.3231e-04 - val_acc: 0.5059\n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s 71us/step - loss: 2.8967e-04 - acc: 0.4710 - val_loss: 4.3167e-04 - val_acc: 0.4408\n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s 80us/step - loss: 2.6674e-04 - acc: 0.4605 - val_loss: 4.0627e-04 - val_acc: 0.4970\n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s 70us/step - loss: 2.5401e-04 - acc: 0.4802 - val_loss: 3.9940e-04 - val_acc: 0.4793\n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s 62us/step - loss: 2.3772e-04 - acc: 0.4842 - val_loss: 3.7398e-04 - val_acc: 0.5237\n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s 59us/step - loss: 2.7371e-04 - acc: 0.4628 - val_loss: 4.2677e-04 - val_acc: 0.4408\n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s 69us/step - loss: 2.9460e-04 - acc: 0.4493 - val_loss: 4.1451e-04 - val_acc: 0.4408\n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s 69us/step - loss: 2.7948e-04 - acc: 0.4460 - val_loss: 4.2451e-04 - val_acc: 0.4497\n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s 89us/step - loss: 2.4261e-04 - acc: 0.4615 - val_loss: 3.6598e-04 - val_acc: 0.5089\n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s 72us/step - loss: 2.2024e-04 - acc: 0.4707 - val_loss: 3.7375e-04 - val_acc: 0.4586\n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s 63us/step - loss: 2.3167e-04 - acc: 0.4783 - val_loss: 3.7006e-04 - val_acc: 0.5325\n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s 61us/step - loss: 2.2548e-04 - acc: 0.4865 - val_loss: 3.9592e-04 - val_acc: 0.4852\n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s 66us/step - loss: 2.3464e-04 - acc: 0.4779 - val_loss: 3.4726e-04 - val_acc: 0.5385\n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s 78us/step - loss: 2.4862e-04 - acc: 0.4690 - val_loss: 3.8756e-04 - val_acc: 0.4734\n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s 101us/step - loss: 2.2798e-04 - acc: 0.4710 - val_loss: 3.6326e-04 - val_acc: 0.5030\n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s 88us/step - loss: 2.3443e-04 - acc: 0.4694 - val_loss: 3.9080e-04 - val_acc: 0.5089\n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s 105us/step - loss: 2.2639e-04 - acc: 0.4789 - val_loss: 3.6450e-04 - val_acc: 0.5118\n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s 78us/step - loss: 2.4599e-04 - acc: 0.4641 - val_loss: 3.8634e-04 - val_acc: 0.4675\n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s 82us/step - loss: 2.3184e-04 - acc: 0.4651 - val_loss: 3.9595e-04 - val_acc: 0.5118\n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s 91us/step - loss: 2.2494e-04 - acc: 0.4816 - val_loss: 3.8735e-04 - val_acc: 0.4970\n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s 88us/step - loss: 2.1630e-04 - acc: 0.4878 - val_loss: 3.9556e-04 - val_acc: 0.5414\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s 84us/step - loss: 2.3172e-04 - acc: 0.4832 - val_loss: 4.1389e-04 - val_acc: 0.5030\n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s 69us/step - loss: 2.5055e-04 - acc: 0.4681 - val_loss: 3.8635e-04 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s 74us/step - loss: 2.3351e-04 - acc: 0.4667 - val_loss: 3.9313e-04 - val_acc: 0.5059\n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s 71us/step - loss: 2.2837e-04 - acc: 0.4710 - val_loss: 3.6978e-04 - val_acc: 0.4911\n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s 105us/step - loss: 2.1986e-04 - acc: 0.4736 - val_loss: 3.6922e-04 - val_acc: 0.4882\n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s 71us/step - loss: 2.4421e-04 - acc: 0.4700 - val_loss: 3.8318e-04 - val_acc: 0.4556\n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s 67us/step - loss: 2.2051e-04 - acc: 0.4819 - val_loss: 3.6066e-04 - val_acc: 0.5325\n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s 70us/step - loss: 2.3852e-04 - acc: 0.4763 - val_loss: 4.0484e-04 - val_acc: 0.4704\n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s 89us/step - loss: 2.4612e-04 - acc: 0.4773 - val_loss: 4.0473e-04 - val_acc: 0.4822\n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s 90us/step - loss: 2.6822e-04 - acc: 0.4743 - val_loss: 3.9206e-04 - val_acc: 0.4793\n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s 67us/step - loss: 2.6609e-04 - acc: 0.4736 - val_loss: 4.3127e-04 - val_acc: 0.5030\n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s 83us/step - loss: 2.4357e-04 - acc: 0.4674 - val_loss: 3.9655e-04 - val_acc: 0.4734\n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s 81us/step - loss: 2.2528e-04 - acc: 0.4628 - val_loss: 3.8578e-04 - val_acc: 0.4586\n",
      "Epoch 61/100\n",
      "1920/3036 [=================>............] - ETA: 0s - loss: 2.2648e-04 - acc: 0.4781"
     ]
    }
   ],
   "source": [
    "encoding_dim = 32\n",
    "input_size = int(data.shape[1])\n",
    "input_dim = Input(shape = (input_size, ))\n",
    "\n",
    "def encoder(input_dim):\n",
    "    encoded1 = Dense(int(input_size/2), activation = 'elu')(input_dim)\n",
    "    encoded2 = Dense(int(input_size/4), activation = 'elu')(encoded1)\n",
    "    encoded3 = Dense(encoding_dim, activation = 'elu')(encoded2)\n",
    "    return encoded3\n",
    "\n",
    "def decoder(encoded3):\n",
    "    decoded1 = Dense(int(input_size/4), activation = 'elu')(encoded3)\n",
    "    decoded2 = Dense(int(input_size/2), activation = 'elu')(decoded1)\n",
    "    decoded3 = Dense(input_size, activation = 'linear')(decoded2)\n",
    "    return decoded3\n",
    "\n",
    "ae3l = Model(inputs = input_dim, output=decoder(encoder(input_dim)))\n",
    "adam = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "ae3l.compile(optimizer = adam, loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "ae3l.summary()\n",
    "\n",
    "# checkpoint\n",
    "# filepath=\"Autoencoder_weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "ae3l.fit(X_train, X_train, nb_epoch = 100, batch_size = 64, shuffle = False, validation_data = (X_test, X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationNN(encode):\n",
    "    dnn4l = Dense(32, activation='relu')(encode)\n",
    "    dnn4l = Dropout(0.1)(dnn4l)\n",
    "    dnn4l = Dense(16, activation='relu')(dnn4l)\n",
    "    dnn4l = Dropout(0.1)(dnn4l)\n",
    "    dnn4l = Dense(8, activation='relu')(dnn4l)\n",
    "    dnn4l = Dropout(0.1)(dnn4l)\n",
    "    dnn4l = Dense(2, activation='softmax')(dnn4l)\n",
    "    return dnn4l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder(input_dim)\n",
    "full_model = Model(input_dim, classificationNN(encode))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "for l1,l2 in zip(full_model.layers[:4],ae3l.layers[0:4]):\n",
    "    l1.set_weights(l2.get_weights())\n",
    "    \n",
    "print(full_model.summary())\n",
    "    \n",
    "# filepath=\"NeuralNet_weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "classify_train = full_model.fit(X_train, Y_train, batch_size=32,epochs=100,verbose=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = classify_train\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
