{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "%config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Dropout, InputLayer\n",
    "from keras.models import Model, Sequential\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file_name):\n",
    "    data = pd.read_csv(csv_file_name)\n",
    "    target = data['label']\n",
    "    data = data.drop(['label'], axis=1)\n",
    "    data = data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1)\n",
    "\n",
    "    data = data.values\n",
    "    target = np.array(target)\n",
    "    target = to_categorical(target)\n",
    "    print(data.shape, target.shape)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 260) (1992, 2)\n",
      "(1792, 260) (1792, 2) (200, 260) (200, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahesh/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = 'apk_permission_151.csv'\n",
    "csv_file_name1 = 'apk_permission_206.csv'\n",
    "data, target = load_data(csv_file_name1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, train_size = 0.9, random_state = seed(2017))\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationNN(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(input_dim,)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1792 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 0.4119 - acc: 0.8326 - val_loss: 0.3135 - val_acc: 0.8550\n",
      "Epoch 2/200\n",
      "1792/1792 [==============================] - 0s 58us/step - loss: 0.2323 - acc: 0.9169 - val_loss: 0.2671 - val_acc: 0.8900\n",
      "Epoch 3/200\n",
      "1792/1792 [==============================] - 0s 54us/step - loss: 0.2031 - acc: 0.9202 - val_loss: 0.2412 - val_acc: 0.8900\n",
      "Epoch 4/200\n",
      "1792/1792 [==============================] - 0s 71us/step - loss: 0.1812 - acc: 0.9342 - val_loss: 0.2710 - val_acc: 0.8900\n",
      "Epoch 5/200\n",
      "1792/1792 [==============================] - 0s 92us/step - loss: 0.1596 - acc: 0.9397 - val_loss: 0.2191 - val_acc: 0.9200\n",
      "Epoch 6/200\n",
      "1792/1792 [==============================] - 0s 81us/step - loss: 0.1382 - acc: 0.9498 - val_loss: 0.2217 - val_acc: 0.9100\n",
      "Epoch 7/200\n",
      "1792/1792 [==============================] - 0s 72us/step - loss: 0.1203 - acc: 0.9593 - val_loss: 0.2079 - val_acc: 0.9150\n",
      "Epoch 8/200\n",
      "1792/1792 [==============================] - 0s 65us/step - loss: 0.1231 - acc: 0.9526 - val_loss: 0.2145 - val_acc: 0.9200\n",
      "Epoch 9/200\n",
      "1792/1792 [==============================] - 0s 67us/step - loss: 0.1005 - acc: 0.9688 - val_loss: 0.2489 - val_acc: 0.9200\n",
      "Epoch 10/200\n",
      "1792/1792 [==============================] - 0s 54us/step - loss: 0.1028 - acc: 0.9632 - val_loss: 0.2279 - val_acc: 0.9200\n",
      "Epoch 11/200\n",
      "1792/1792 [==============================] - 0s 64us/step - loss: 0.0865 - acc: 0.9738 - val_loss: 0.2630 - val_acc: 0.9100\n",
      "Epoch 12/200\n",
      "1792/1792 [==============================] - 0s 66us/step - loss: 0.0882 - acc: 0.9727 - val_loss: 0.2368 - val_acc: 0.9250\n",
      "Epoch 13/200\n",
      "1792/1792 [==============================] - 0s 54us/step - loss: 0.0848 - acc: 0.9743 - val_loss: 0.2462 - val_acc: 0.9250\n",
      "Epoch 14/200\n",
      "1792/1792 [==============================] - 0s 59us/step - loss: 0.0876 - acc: 0.9715 - val_loss: 0.2383 - val_acc: 0.9100\n",
      "Epoch 15/200\n",
      "1792/1792 [==============================] - 0s 64us/step - loss: 0.0764 - acc: 0.9743 - val_loss: 0.2100 - val_acc: 0.9100\n",
      "Epoch 16/200\n",
      "1792/1792 [==============================] - 0s 63us/step - loss: 0.0828 - acc: 0.9727 - val_loss: 0.2400 - val_acc: 0.9200\n",
      "Epoch 17/200\n",
      "1792/1792 [==============================] - 0s 59us/step - loss: 0.0708 - acc: 0.9788 - val_loss: 0.2650 - val_acc: 0.9000\n",
      "Epoch 18/200\n",
      "1792/1792 [==============================] - 0s 59us/step - loss: 0.0779 - acc: 0.9754 - val_loss: 0.2543 - val_acc: 0.9200\n",
      "Epoch 19/200\n",
      "1792/1792 [==============================] - 0s 57us/step - loss: 0.0720 - acc: 0.9794 - val_loss: 0.2696 - val_acc: 0.9050\n",
      "Epoch 20/200\n",
      "1792/1792 [==============================] - 0s 56us/step - loss: 0.0776 - acc: 0.9760 - val_loss: 0.2467 - val_acc: 0.9150\n",
      "Epoch 21/200\n",
      "1792/1792 [==============================] - 0s 53us/step - loss: 0.0656 - acc: 0.9805 - val_loss: 0.2497 - val_acc: 0.9050\n",
      "Epoch 22/200\n",
      "1792/1792 [==============================] - 0s 55us/step - loss: 0.0627 - acc: 0.9799 - val_loss: 0.2208 - val_acc: 0.9100\n",
      "Epoch 23/200\n",
      "1792/1792 [==============================] - 0s 55us/step - loss: 0.0671 - acc: 0.9788 - val_loss: 0.2552 - val_acc: 0.9050\n",
      "Epoch 24/200\n",
      "1792/1792 [==============================] - 0s 54us/step - loss: 0.0545 - acc: 0.9821 - val_loss: 0.3495 - val_acc: 0.9050\n",
      "Epoch 25/200\n",
      "1792/1792 [==============================] - 0s 59us/step - loss: 0.0643 - acc: 0.9788 - val_loss: 0.2635 - val_acc: 0.9050\n",
      "Epoch 26/200\n",
      "1792/1792 [==============================] - 0s 57us/step - loss: 0.0645 - acc: 0.9799 - val_loss: 0.2860 - val_acc: 0.9100\n",
      "Epoch 27/200\n",
      "1792/1792 [==============================] - 0s 69us/step - loss: 0.0792 - acc: 0.9727 - val_loss: 0.2615 - val_acc: 0.9050\n",
      "Epoch 28/200\n",
      "1792/1792 [==============================] - 0s 93us/step - loss: 0.0623 - acc: 0.9794 - val_loss: 0.2735 - val_acc: 0.9200\n",
      "Epoch 29/200\n",
      "1792/1792 [==============================] - 0s 75us/step - loss: 0.0612 - acc: 0.9782 - val_loss: 0.3291 - val_acc: 0.9150\n",
      "Epoch 30/200\n",
      "1792/1792 [==============================] - 0s 60us/step - loss: 0.0560 - acc: 0.9805 - val_loss: 0.3237 - val_acc: 0.9100\n",
      "Epoch 31/200\n",
      "1792/1792 [==============================] - 0s 69us/step - loss: 0.0700 - acc: 0.9788 - val_loss: 0.2673 - val_acc: 0.9100\n",
      "Epoch 32/200\n",
      "1792/1792 [==============================] - 0s 80us/step - loss: 0.0644 - acc: 0.9788 - val_loss: 0.2847 - val_acc: 0.9100\n",
      "Epoch 33/200\n",
      "1792/1792 [==============================] - 0s 74us/step - loss: 0.0542 - acc: 0.9799 - val_loss: 0.3258 - val_acc: 0.9100\n",
      "Epoch 34/200\n",
      "1792/1792 [==============================] - 0s 57us/step - loss: 0.0541 - acc: 0.9810 - val_loss: 0.3177 - val_acc: 0.9050\n",
      "Epoch 35/200\n",
      "1792/1792 [==============================] - 0s 82us/step - loss: 0.0493 - acc: 0.9838 - val_loss: 0.3323 - val_acc: 0.9150\n",
      "Epoch 36/200\n",
      "1792/1792 [==============================] - 0s 64us/step - loss: 0.0528 - acc: 0.9810 - val_loss: 0.3670 - val_acc: 0.9200\n",
      "Epoch 37/200\n",
      "1792/1792 [==============================] - 0s 47us/step - loss: 0.0672 - acc: 0.9754 - val_loss: 0.3160 - val_acc: 0.9050\n",
      "Epoch 38/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0615 - acc: 0.9794 - val_loss: 0.2990 - val_acc: 0.9200\n",
      "Epoch 39/200\n",
      "1792/1792 [==============================] - 0s 52us/step - loss: 0.0546 - acc: 0.9816 - val_loss: 0.2807 - val_acc: 0.9100\n",
      "Epoch 40/200\n",
      "1792/1792 [==============================] - 0s 48us/step - loss: 0.0475 - acc: 0.9838 - val_loss: 0.3319 - val_acc: 0.9100\n",
      "Epoch 41/200\n",
      "1792/1792 [==============================] - 0s 47us/step - loss: 0.0496 - acc: 0.9816 - val_loss: 0.3434 - val_acc: 0.9150\n",
      "Epoch 42/200\n",
      "1792/1792 [==============================] - 0s 51us/step - loss: 0.0485 - acc: 0.9827 - val_loss: 0.3383 - val_acc: 0.9100\n",
      "Epoch 43/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0590 - acc: 0.9794 - val_loss: 0.2963 - val_acc: 0.9200\n",
      "Epoch 44/200\n",
      "1792/1792 [==============================] - 0s 51us/step - loss: 0.0631 - acc: 0.9766 - val_loss: 0.2551 - val_acc: 0.9250\n",
      "Epoch 45/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0498 - acc: 0.9821 - val_loss: 0.2667 - val_acc: 0.9400\n",
      "Epoch 46/200\n",
      "1792/1792 [==============================] - 0s 55us/step - loss: 0.0516 - acc: 0.9810 - val_loss: 0.3513 - val_acc: 0.9200\n",
      "Epoch 47/200\n",
      "1792/1792 [==============================] - 0s 61us/step - loss: 0.0529 - acc: 0.9833 - val_loss: 0.2704 - val_acc: 0.9150\n",
      "Epoch 48/200\n",
      "1792/1792 [==============================] - 0s 68us/step - loss: 0.0465 - acc: 0.9838 - val_loss: 0.2970 - val_acc: 0.9250\n",
      "Epoch 49/200\n",
      "1792/1792 [==============================] - 0s 58us/step - loss: 0.0551 - acc: 0.9782 - val_loss: 0.3478 - val_acc: 0.9050\n",
      "Epoch 50/200\n",
      "1792/1792 [==============================] - 0s 55us/step - loss: 0.0585 - acc: 0.9777 - val_loss: 0.3493 - val_acc: 0.9100\n",
      "Epoch 51/200\n",
      "1792/1792 [==============================] - 0s 50us/step - loss: 0.0543 - acc: 0.9788 - val_loss: 0.3522 - val_acc: 0.9200\n",
      "Epoch 52/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0488 - acc: 0.9816 - val_loss: 0.3414 - val_acc: 0.9200\n",
      "Epoch 53/200\n",
      "1792/1792 [==============================] - 0s 47us/step - loss: 0.0467 - acc: 0.9844 - val_loss: 0.3413 - val_acc: 0.9150\n",
      "Epoch 54/200\n",
      "1792/1792 [==============================] - 0s 50us/step - loss: 0.0419 - acc: 0.9849 - val_loss: 0.3557 - val_acc: 0.9250\n",
      "Epoch 55/200\n",
      "1792/1792 [==============================] - 0s 50us/step - loss: 0.0459 - acc: 0.9844 - val_loss: 0.3521 - val_acc: 0.9200\n",
      "Epoch 56/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0450 - acc: 0.9844 - val_loss: 0.4179 - val_acc: 0.9200\n",
      "Epoch 57/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0454 - acc: 0.9833 - val_loss: 0.3785 - val_acc: 0.9100\n",
      "Epoch 58/200\n",
      "1792/1792 [==============================] - 0s 52us/step - loss: 0.0438 - acc: 0.9833 - val_loss: 0.3576 - val_acc: 0.9200\n",
      "Epoch 59/200\n",
      "1792/1792 [==============================] - 0s 59us/step - loss: 0.0434 - acc: 0.9844 - val_loss: 0.3675 - val_acc: 0.9150\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/1792 [==============================] - 0s 58us/step - loss: 0.0469 - acc: 0.9821 - val_loss: 0.3700 - val_acc: 0.9150\n",
      "Epoch 61/200\n",
      "1792/1792 [==============================] - 0s 49us/step - loss: 0.0453 - acc: 0.9827 - val_loss: 0.3370 - val_acc: 0.9150\n",
      "Epoch 62/200\n",
      "1792/1792 [==============================] - 0s 53us/step - loss: 0.0728 - acc: 0.9782 - val_loss: 0.2981 - val_acc: 0.9200\n",
      "Epoch 63/200\n",
      "1792/1792 [==============================] - 0s 65us/step - loss: 0.0610 - acc: 0.9799 - val_loss: 0.2905 - val_acc: 0.9150\n",
      "Epoch 64/200\n",
      "1600/1792 [=========================>....] - ETA: 0s - loss: 0.0489 - acc: 0.9819"
     ]
    }
   ],
   "source": [
    "model = classificationNN(data.shape[1])\n",
    "sgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# filepath=\"ModelWeights/ModelWeight_Permission/Permissions_Neural_\" + csv_file_name.split('.')[0] + \".hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=32,epochs=200,verbose=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(data, target)\n",
    "# with open(\"malware_classifier.dot\", \"w\") as ic:\n",
    "#     ic = tree.export_graphviz(clf, out_file = ic, feature_names=column_names)\n",
    "# os.system('dot -Tpdf malware_classifier.dot -o malware_clf1.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
